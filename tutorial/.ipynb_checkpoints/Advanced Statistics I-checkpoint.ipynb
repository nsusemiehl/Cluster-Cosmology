{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Statistics: Bayes/MLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the mid-eighteenth century, one of the most pressing mathematical problems was how to improve your odds of winning a game of chance:\n",
    "\n",
    "<blockquote>\n",
    "<i>\"Let us then imagine a person present at the drawing of a lottery, who knows nothing of its scheme or of the proportion of Blanks to Prizes in it. Let it further be supposed, that he is obliged to infer this from the number of blanks he hears drawn compared with the number of prizes; and that it is enquired what conclusions in these circumstances he may reasonably make.</i>\n",
    "\n",
    "<br/><br/>\n",
    "\n",
    "<i>Let him first hear ten blanks drawn and one prize, and let it be enquired what chance he will have for being right if he guesses that the proportion of blanks to prizes in the lottery lies somewhere between the proportions of 9 to 1 and 11 to 1.\"</i>\n",
    "</blockquote>\n",
    "\n",
    "<p style=\"text-align:right\">An Essay towards solving a Problem in the Doctrine of Chances by Rev. T. Bayes (1763)</p>\n",
    "\n",
    "This was the problem of inverse probability, determining the distribution of an unobserved variable given data: in this case, the probability of winning a prize in a lottery. Let's first assume that the probability of winning, $p$, is a random variable uniformly distributed between 0 and 1 (this is probably the most specific statement we can make about it as we have no further information about it). The result of each draw, $X_i$, is then a variable conditional on the value of $p$, such that for a given draw, $p(X = 1) = p$ (for a prize) and $p(X = 0) = (1 - p)$ for a blank, but independent of any other draw. After $n+m$ draws, there will have been $m$ prizes and $n$ blanks which will have a probability density function given by:\n",
    "\n",
    "$$\n",
    "f(n,m) = \\frac{(n + m)!}{m!n!}p^m(1-p)^n = \\left( \\frac{n+m}{m} \\right) p^m (1-p)^n\n",
    "$$\n",
    "\n",
    "The chance that $p$ lies between two values $a$ and $b$ given the observed values of $m$ and $n$ is then:\n",
    "\n",
    "$$\n",
    "P(a < p < b \\mid m,n) = \\frac{\\int_a^b \\left( \\frac{n+m}{m} \\right) p^m (1-p)^n dp} {\\int_0^1 \\left( \\frac{n+m}{m} \\right) p^m (1-p)^n dp}\n",
    "$$\n",
    "\n",
    "where the denominator provides the normalization over all possible values of $p$ so that $P(0 < p < 1) = 1$. You might recognize the normalized integrand as the beta distribution. For $a = 1 / 11, b = 1 / 9, m = 1$ and $n = 10$, this gives a probability of about 0.077 or, as Bayes put it: <i>\"there would therefore be an odds of about 923 to 76, or nearly 12 to 1 <b>against</b> his being right\"</i>. The results of further draws can also be easily determined, hopefully giving better odds.\n",
    "\n",
    "Today we would call this an example of statistical inferencing and use Bayesian probability to solve it. The distribution of the data, $n$ and $m$, for a given value of the unobserved variable, $p$, is the likelihood function, $p(D \\mid M)$; the initial assumption of the distribution of $p$ is the prior, $p(M)$; the denominator is the marginal likelihood or evidence; and the final result is the posterior probability, $p(M \\mid D)$, all of which are related by Bayes' Theorem:\n",
    "\n",
    "$$ P(M \\mid D) = \\frac{P(D \\mid M) P(M)}{P(D)} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choice of prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, we assume a uniform distribution or what is normally called a <i>flat prior</i> or an <i>uninformative</i> prior:\n",
    "\n",
    "$$p(\\theta) = const., \\,\\, a < \\theta < b $$\n",
    "\n",
    "This is the recommendation for a parameter which may take any value in a finite range, or from $-\\infty$ to $\\infty$. A subtlety with this choice is that it does not describe a state of complete ignorance, but the state of knowledge in which we have observed at least one success and one failure, and have prior knowledge that both states are physically possible.\n",
    "\n",
    "If the parameter is limited to positive real values then the prior should be uniform in the logarithmic range:\n",
    "\n",
    "$$p(\\theta) \\propto \\theta^{-1} => p(\\ln \\theta) = const $$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jeffrey's rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general recommendation for an uninformative prior is Jeffrey's rule which gives the prior as the square root of the determinant of the <i>Fisher information</i> for the model:\n",
    "\n",
    "$$p(\\theta) \\propto \\sqrt{\\det \\cal I(\\theta)}$$\n",
    "\n",
    "where $\\cal I(\\theta)$ is the second moment (variance) of the partial derivative with respect to $\\theta$ of the natural logarithm of the likelihood function for $\\theta$:\n",
    "\n",
    "$$\\cal I(\\theta) = \\mathrm{E} \\left[ \\left( \\frac{\\partial}{\\partial \\theta} \\log f(\\theta) \\right)^2 \\right] = -\\mathrm{E} \\left[ \\frac{\\partial^2}{\\partial \\theta^2} \\log f(\\theta)  \\right]$$\n",
    "\n",
    "For example, if you believe that your data is drawn from a Gaussian distribution with an unknown mean then the likelihood function for the mean is:\n",
    "\n",
    "$$f(x \\mid \\mu) = \\frac{e^{-(x-\\mu)^2/2\\sigma^2}}{\\sqrt{2\\pi\\sigma^2}} $$\n",
    "\n",
    "(with a fixed $\\sigma$) and the prior for the mean is:\n",
    "\n",
    "$$ p(\\mu) \\propto \\sqrt{\\mathrm{E}\\left[ \\left(\\frac{x-\\mu}{\\sigma^2}\\right)^2 \\right]} = \\sqrt{\\int_{-\\infty}^{+\\infty} f(x \\mid \\mu) \\left( \\frac{x - \\mu}{\\sigma^2} \\right)^2 dx} = \\frac{1}{\\sigma}$$\n",
    "\n",
    "This is just a constant and so the appropriate prior is the uniform distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, what we really want is some measure that captures the <i>information content</i> of a distribution and then assign a prior that reflects our ignorance of the true value of a parameter by optimizing this quantity accordingly. Such a quantity is the <i>Shannon entropy</i>:\n",
    "\n",
    "$$ S(p_1,p_2,...,p_n) = \\sum_{i=1}^n p_i \\ln p_i $$\n",
    "\n",
    "which behaves like thermodynamic entropy such that increasing entropy means less information. The <i>maximum entropy</i> prior is then the probability distribution, $p(x)$, that maximizes:\n",
    "\n",
    "$$ S = - \\int dx \\,\\, p(x) \\ln p(x) $$\n",
    "\n",
    "For example, let's suppose that we know that the variance, $\\sigma^2$, is finite but nothing else. A finite mean must exist yet we don't know what it is but we can find the maximum entropy prior for an arbitrary mean, $\\mu$. Let's define a (Lagrangian) function:\n",
    "\n",
    "$$ L =  -\\int_{-\\infty}^{\\infty} p(x) \\ln p(x) dx + \\lambda_0 \\left(\\int_{-\\infty}^{\\infty} p(x) dx - 1 \\right) + \\lambda_1 \\left( \\int_{-\\infty}^\\infty (x - \\mu)^2 p(x) dx - \\sigma^2 \\right) $$\n",
    "\n",
    "where $\\lambda_0$ is the Lagrange multiplier for the probability normalization constraint $\\int_{-\\infty}^{\\infty} p(x) dx = 1$ and $\\lambda_1$ is the constraint for the finite variance $\\sigma^2 = \\int_{-\\infty}^\\infty (x - \\mu)^2 p(x) dx$. The necessary condition for an extremum to exist is that $\\delta L = 0$:\n",
    "\n",
    "$$ -\\ln p(x) - 1 + \\lambda_0 + \\lambda_1 (x - \\mu)^2 = 0 $$\n",
    "\n",
    "and so:\n",
    "\n",
    "$$ p(x) = \\exp(\\lambda_0 - 1 + \\lambda_1 (x - \\mu)^2) $$\n",
    "\n",
    "Using the constraint equations to solve for $\\lambda_0$ and $\\lambda_1$ then gives:\n",
    "\n",
    "$$ p(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp \\left( - \\frac{(x - \\mu)^2}{2 \\sigma^2} \\right) $$\n",
    "\n",
    "So among all real-valued distributions with a specified variance, $\\sigma^2$, the Gaussian distribution has the maximum entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis testing is a core application of statistical methodology in science. The standard approach is to compute some test statistic from a data set and then determine the probability (p-value) under the <i>null hypothesis</i> of sampling a value at least as extreme as the observed one. If the p-value is less than some preselected threshold level then the null hypothesis is rejected. In the Bayesian approach, the relative likelihoods of the data under each hypothesis are evaluated and their ratio (called the <i>Bayes factor</i>) determines which hypothesis is more strongly supported by the data:\n",
    "\n",
    "$$ \\mathrm{Bayes \\,\\, factor} = \\frac{p(D \\mid M_1)}{p(D \\mid M_2)} = \\frac{\\int p(D \\mid \\theta_1, M_1) \\, p(\\theta_1 \\mid M_1) \\, d\\theta_1}{\\int p(D \\mid \\theta_2, M_2) \\, p(\\theta_2 \\mid M_2) \\, d\\theta_2}$$\n",
    "\n",
    "where $\\theta_k$ is a parameter associated with $M_k$, $p(\\theta_k \\mid M_k)$ is its prior and $p(D \\mid \\theta_k, M_k)$ is the likelihood function of $\\theta$, or, in other words, the posterior odds = Bayes factor $\\times$ prior odds. The Bayes factor, $K$, is then a summary of the evidence provided by data in favor of one scientific theory in contrast to another with interprative values:\n",
    "\n",
    "<table>\n",
    "<tr><th>$2 \\ln K$</th><th>K</th><th>Strength of evidence</th></tr>\n",
    "<tr><td>0 - 2</td><td>1 - 3</td><td>Not worth more than a bare mention</td></tr>\n",
    "<tr><td>2 - 6</td><td>3 - 20</td><td>Positive</td></tr>\n",
    "<tr><td>6 - 10</td><td>20 - 150</td><td>Strong</td></tr>\n",
    "<tr><td>&gt; 10</td><td>&gt; 150</td><td>Very strong</td></tr>\n",
    "</table>\n",
    "\n",
    "For example, a study of whether test subjects could use psychokinesis to influence the random output of electronic random event generators reported 52263471 successes out of 104490000 Bernouilli trials, which is a ratio of 0.5001768. Assuming a null hypothesis that the ratio should be 0.5 in the absence of any effect, we get a p-value of 0.0003 ($3.614 \\sigma$) from which we conclude that ESP is real. Alternatively, we can evaluate the Bayes factor with $\\theta_1 = 0.5$ for model 1 (null hypothesis) and an unknown $\\theta_2$ for model 2 using the Jeffrey's prior for a Bernouilli distribution, $f(\\theta) = 1/\\sqrt{(\\theta (1 - \\theta))}$:\n",
    "\n",
    "$$ K = \\frac{p(D \\mid \\theta_1 = 0.5)}{\\int_0^1 p(D \\mid \\theta_2)f(\\theta_2) d\\theta_2} = \\frac{\\pi \\cdot 0.5^N}{B(S + 0.5, N - S + 0.5)} = e^{2.93} = 18.7$$\n",
    "\n",
    "so there is positive evidence against ESP. For a uniform prior, $K \\sim 15.4$. \n",
    "\n",
    "<figure>\n",
    "<img src=\"http://imgs.xkcd.com/comics/frequentists_vs_bayesians.png\"/>\n",
    "<figcaption style=\"text-align:center\"><b> </b></figcaption>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Likelihood Estimation (MLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The likelihood of a data set given a particular model is the joint probability of each individual data point given the model:\n",
    "\n",
    "$$ L \\equiv p(\\{x_i\\} \\mid M(\\theta)) = \\prod_{i = 1}^n p(x_i \\mid M(\\theta)) $$\n",
    "\n",
    "although it is often useful to deal instead with the log-likelihood:\n",
    "\n",
    "$$ L = \\prod_{i = 1}^n \\ln (p(x_i \\mid M(\\theta))) $$\n",
    "\n",
    "Now if we are interested in determining the best-fit form of a model to a data set, i.e. the best-fit values of a model's parameters, $\\theta_i$, to a particular $\\{x_i\\}$, then the likelihood will obviously be maximized for these values. Thus solving for the $\\theta_i, i = 1,...,n$, that maximize the likelihood is one way to determine the optimal fit:\n",
    "\n",
    "$$  \\frac{\\partial L}{\\partial \\theta_i}(x_i, \\hat{\\theta}_i) = 0 $$ \n",
    "\n",
    "For example, suppose we want to fit a data set with a power law (Pareto) model of the form, $f = a x_m^{\\alpha} / x^{\\alpha + 1}$ for $x \\ge x_m$. The likelihood is:\n",
    "\n",
    "$$ L = \\prod_{i = 1}^n  \\alpha x_m^{\\alpha} / x^{\\alpha + 1} $$\n",
    "\n",
    "which gives a log-likelihood of:\n",
    "\n",
    "$$ \\ln L = n \\ln \\alpha + n \\alpha \\ln x_m - (\\alpha + 1) \\sum_{i=1}^{n} \\ln x_i $$\n",
    "\n",
    "Finding the extremum gives:\n",
    "\n",
    "$$ \\frac{\\partial \\ln L}{\\partial \\alpha} = \\frac{n}{\\alpha} + n \\ln x_m - \\sum_{i=1}^n \\ln x_i = 0 $$\n",
    "\n",
    "and so:\n",
    "\n",
    "$$ \\hat{\\alpha} = \\frac{1}{\\sum_{i=1}^n \\ln x_i / n - \\ln x_m} $$\n",
    "\n",
    "As the sample size increases, the distribution of the MLE tends to the Gaussian distribution with mean $\\theta$ and covariance matrix equal to the inverse of the Fisher information matrix, $\\cal{I}(\\theta)$. Recall from earlier that the Fisher information matrix is given by:\n",
    "\n",
    "$$ \\cal{I}(\\theta) = -\\mathrm{E} \\left[ \\frac{\\partial^2}{\\partial \\theta^2} \\log f(\\theta)  \\right]$$\n",
    "\n",
    "so in the case of the Pareto model, this is:\n",
    "\n",
    "$$ \\cal{I}(\\alpha) = \\frac{n}{\\alpha^2} $$\n",
    "\n",
    "The (asymptotic) error on the best-fit parameter, $\\hat{\\alpha}$, is thus given by a Gaussian with mean $\\hat{\\alpha}$ and variance $\\alpha^2 / n$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum a posteriori (MAP) estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MLE can be regarded as the most probable Bayesian estimator assuming a flat prior. However, if we have more (some) information about the parameters we are trying to fit then a better estimate can be obtained which incorporates this information via the maximum a postriori estimate. Formally this is defined as the <b>mode</b> of the posterior distribution of the parameter which is just the product of the likelihood and the prior:\n",
    "\n",
    "$$ \\hat{\\theta}_{MAP} = \\arg \\max_{\\theta} L(\\{x_i\\} \\mid \\theta) p(\\theta) $$\n",
    "\n",
    "For example, suppose that we want to fit a Gaussian model to a data set and we also believe that the mean, $\\mu$, is drawn from a different Gaussian distribution with mean $\\mu_0$ and variance $\\sigma_m^2$. The posterior to be maximized is then:\n",
    "\n",
    "$$ L(\\{x_i\\} \\mid \\mu)p(\\mu) = \\frac{1}{\\sqrt{2 \\pi} \\sigma_m} \\exp \\left( -\\frac{1}{2} \\left( \\frac{\\mu - \\mu_0}{\\sigma_m^2} \\right)^2 \\right) \\prod_{j=1}^{n} \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left( -\\frac{1}{2} \\left( \\frac{x_j - \\mu}{\\sigma^2} \\right)^2 \\right) $$\n",
    "\n",
    "From this, the MAP estimator for $\\mu$ is:\n",
    "\n",
    "$$ \\hat{\\mu}_{MAP} = \\frac{n\\sigma_m^2}{n\\sigma_m^2+\\sigma^2}\\left(\\frac{1}{n}\\sum_{j=1}^n x_j \\right) + \\frac{\\sigma^2}{n\\sigma_m^2 + \\sigma^2}\\mu_0 $$\n",
    "\n",
    "which is a linear interpolation between the prior mean and the sample mean weighted by their respective covariances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naïve Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now consider the case when the parameter we are trying to fit to a set of features, $\\{x_i, i = 1,\\ldots,n\\}$, is a (discrete) class label, $y$:\n",
    "\n",
    "$$ p(y \\mid \\{x_i\\}) = \\frac{p(\\{x_i\\} \\mid y) p (y)}{p(\\{x_i\\})} $$ \n",
    "\n",
    "Under the naïve assumption that all the features are conditionally independent, i.e., $p(x_i \\mid y, x_1,\\ldots,x_{i-1},x_{i+1},\\ldots,x_n) = p(x_i \\mid y)$, this becomes:\n",
    "\n",
    "$$ p(y \\mid \\{x_i\\}) \\propto p (y) \\prod_{i=1}^n p(x_i \\mid y) $$ \n",
    "\n",
    "for which we can get a best class estimate via MAP:\n",
    "\n",
    "$$ \\hat{y} = \\arg \\max_{y_k} p(y) \\prod_{i=1}^n p(x_i \\mid y) $$\n",
    "\n",
    "The class prior can be estimated from the relative frequencies of different class values in the training set or by assuming equiprobable classes. Similarly, an assumption needs to be made about the distribution of the features relative to the class value. When categorical (discrete) features are used, the relative frequencies of each feature value for a given class value suffices. In the case when $p(x_i) = 0$ for some value of $y$, i.e., a given class and feature value never occur together in the training set, a offset (pseudocount) value $\\alpha$ is added to the probability of each bin (known as Laplace smoothing) to ensure that the posterior probability does not blow up ($p(y \\mid x) = 0 / 0$).\n",
    "\n",
    "With continuous feature values, we make an assumption about their distribution associated with each class. For example,\n",
    "\n",
    "$$ p(x_i \\mid y) = \\frac{1}{\\sqrt{2 \\pi} \\sigma_y} \\exp \\left( - \\frac{(x_i - \\mu_y)^2}{2 \\sigma_y^2} \\right) $$\n",
    "\n",
    "where each class has a different mean and variance (and can be estimated via MLE). In this case, we then get the best class estimates for data as:\n",
    "\n",
    "$$ \\hat{y} = \\arg \\max_{y_k} \\left[ \\ln p(y_k) - \\frac{1}{2} \\sum_{i=1}^N \\left( 2\\pi\\sigma_y^2 + \\frac{(x_i - \\mu_y)^2}{\\sigma_y^2} \\right) \\right] $$ \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, there are already implementations of this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAD7CAYAAAChScXIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSNIWQggj8v9ZK69DQXpBqAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x101fbe150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate some random data\n",
    "np.random.seed(0)\n",
    "mu1 = [1, 1]\n",
    "cov1 = 0.3 * np.eye(2)\n",
    "mu2 = [5, 3]\n",
    "cov2 = np.eye(2) * np.array([0.4, 0.1])\n",
    "X = np.concatenate([np.random.multivariate_normal(mu1, cov1, 100), np.random.multivariate_normal(mu2, cov2, 100)])\n",
    "y = np.zeros(200)\n",
    "y[100:] = 1\n",
    "\n",
    "# Fit Gaussian Naive Bayes\n",
    "clf = GaussianNB()\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Predict on a grid\n",
    "xx, yy = np.meshgrid(np.linspace(-1, 8, 71), np.linspace(-1, 5, 81))\n",
    "Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z[:, 1].reshape(xx.shape)\n",
    "\n",
    "# Plot the results\n",
    "fig = plt.figure()\n",
    "ax = fig.gca()\n",
    "ax.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.binary, zorder=2)\n",
    "ax.contour(xx, yy, Z, [0.5], colors='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
